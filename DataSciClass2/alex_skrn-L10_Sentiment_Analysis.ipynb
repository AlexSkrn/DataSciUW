{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 10 - Sentiment Analysis\n",
    "\n",
    "## Author - AlexSkrn\n",
    "\n",
    "This assignment requires that you build a sentiment analysis classifier for a series of tweets.\n",
    "The data consists of a file \"twitter_data.csv\". The file contains 160,000 tweets with their respective score. The attributes are the sentences, and the score is either 4 (for positive) or 0 (for negative).\n",
    "\n",
    "Assignment Instructions\n",
    "1. Complete all questions below.\n",
    "2. Comment on the applicability of the model on future tweets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: This solution is mostly copy-pasted from the lesson 10 materials, with very minor modifications. I asked the group in the code talk section what they thought about this but no one commented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment_label                                         tweet_text\n",
      "0                4  @elephantbird Hey dear, Happy Friday to You  A...\n",
      "1                4  Ughhh layin downnnn    Waiting for zeina to co...\n",
      "2                0  @greeniebach I reckon he'll play, even if he's...\n",
      "3                0              @vaLewee I know!  Saw it on the news!\n",
      "4                0  very sad that http://www.fabchannel.com/ has c...\n"
     ]
    }
   ],
   "source": [
    "#Read files\n",
    "url = \"https://library.startlearninglabs.uw.edu/DATASCI410/Datasets/twitter_data.csv\"\n",
    "df = pandas.read_csv(url, sep=\",\")\n",
    "df.columns = [\"sentiment_label\",\"tweet_text\"]\n",
    "    \n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, list_of_steps):\n",
    "    \"\"\"Return a string cleaned up as per the list of steps.\"\"\"\n",
    "    for step in list_of_steps:\n",
    "        if step == 'remove_non_ascii':\n",
    "            text = ''.join([x for x in text if ord(x) < 128])\n",
    "        elif step == 'lowercase':\n",
    "            text = text.lower()\n",
    "        elif step == 'remove_punctuation':\n",
    "            punct_exclude = set(string.punctuation)\n",
    "            text = ''.join(char for char in text if char not in punct_exclude)\n",
    "        elif step == 'remove_numbers':\n",
    "            text = re.sub(\"\\d+\", \"\", text)\n",
    "        elif step == 'strip_whitespace':\n",
    "            text = ' '.join(text.split())\n",
    "        elif step == 'remove_stopwords':\n",
    "            stops = stopwords.words('english')\n",
    "            word_list = text.split(' ')\n",
    "            text_words = [word for word in word_list if word not in stops]\n",
    "            text = ' '.join(text_words)\n",
    "        elif step == 'stem_words':\n",
    "            lmtzr = WordNetLemmatizer()\n",
    "            word_list = text.split(' ')\n",
    "            stemmed_words = [lmtzr.lemmatize(word) for word in word_list]\n",
    "            text = ' '.join(stemmed_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment is either '4' or '0'. Change to '1' or '0' to indicate positive or negative sentiment.\n",
    "df.sentiment_label = df.sentiment_label.replace(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a copy of the tweets as list for use later\n",
    "tweet_data = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean tweets\n",
    "steps = ['lowercase', 'remove_punctuation', 'remove_numbers', 'strip_whitespace', 'remove_stopwords']\n",
    "\n",
    "df['clean_tweet'] = df['tweet_text'].map(lambda s: preprocess(s, steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry: ['mandyalwaysknws', 'sad', 'day']\n"
     ]
    }
   ],
   "source": [
    "# Create a document storage matrix\n",
    "clean_texts = df['clean_tweet']\n",
    "docs = {}\n",
    "labels = []\n",
    "for ix, row in enumerate(clean_texts):\n",
    "    # Store the sentiment\n",
    "    labels = tweet_data[ix][0]\n",
    "    docs[ix] = row.split(' ')\n",
    "\n",
    "# See a sample\n",
    "print('Example entry: {}'.format(docs[np.random.choice(ix)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our tweet-vocabulary has 151526 distinct words.\n"
     ]
    }
   ],
   "source": [
    "# Keep track of how many unique words there are:\n",
    "num_nonzero = 0\n",
    "vocab = set()\n",
    "\n",
    "for word_list in docs.values():\n",
    "    unique_terms = set(word_list)    # all unique terms of this tweet\n",
    "    vocab.update(unique_terms)       # set union: add unique terms of this tweet\n",
    "    num_nonzero += len(unique_terms) # add count of unique terms in this tweet\n",
    "\n",
    "doc_key_list = list(docs.keys())\n",
    "\n",
    "print('Our tweet-vocabulary has {} distinct words.'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert everything to a numpy array:\n",
    "doc_key_list = np.array(doc_key_list)\n",
    "vocab = np.array(list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['' 'brewin' 'lolatleast' 'wickets' 'lbegleykorth']\n",
      "Sorted Vocab: ['' 'aa' 'aaa' 'aaaa' 'aaaaa']\n"
     ]
    }
   ],
   "source": [
    "# Keep track of how the vocab/term indices map to the matrix so that we can look them up later.\n",
    "vocab_sorter = np.argsort(vocab)\n",
    "\n",
    "print('Vocab: {}'.format(vocab[:5]))\n",
    "print('Sorted Vocab: {}'.format(vocab[vocab_sorter[:5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our sparse matrix:\n",
    "num_docs = len(doc_key_list)\n",
    "vocab_size = len(vocab)\n",
    "# A COO matrix is just a tuple of data, row indices, and column indices. Everything else is assumed to be zero.\n",
    "data = np.empty(num_nonzero, dtype=np.intc)     # all non-zero\n",
    "rows = np.empty(num_nonzero, dtype=np.intc)     # row index\n",
    "cols = np.empty(num_nonzero, dtype=np.intc)     # column index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing full term-document matrix (sparse), please wait!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "ix = 0\n",
    "# go through all documents with their terms\n",
    "print('Computing full term-document matrix (sparse), please wait!')\n",
    "for doc_key, terms in docs.items():\n",
    "    # find indices to insert-into such that, if the corresponding elements were\n",
    "    # inserted before the indices, the order would be preserved\n",
    "    term_indices = vocab_sorter[np.searchsorted(vocab, terms, sorter=vocab_sorter)]\n",
    "\n",
    "    # count the unique terms of the document and get their vocabulary indices\n",
    "    uniq_indices, counts = np.unique(term_indices, return_counts=True)\n",
    "    n_vals = len(uniq_indices)  # = number of unique terms\n",
    "    ix_end = ix + n_vals # Add count to index.\n",
    "\n",
    "    data[ix:ix_end] = counts                  # save the counts (term frequencies)\n",
    "    cols[ix:ix_end] = uniq_indices            # save the column index: index in \n",
    "    doc_ix = np.where(doc_key_list == doc_key)   # get the document index for the document name\n",
    "    rows[ix:ix_end] = np.repeat(doc_ix, n_vals)  # save it as repeated value\n",
    "\n",
    "    ix = ix_end  # resume with next document -> will add future data on the end.\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sparse matrix\n",
    "doc_term_mat = coo_matrix((data, (rows, cols)), shape=(num_docs, vocab_size), dtype=np.intc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words w/counts above 15 : 6095\n"
     ]
    }
   ],
   "source": [
    "# Trimming the Doc-term matrix\n",
    "# Look at how many words are above a specific cutoff\n",
    "word_counts = doc_term_mat.sum(axis=0)\n",
    "cutoff = 15\n",
    "word_count_list = word_counts.tolist()[0]\n",
    "# Find which column indices are above cutoff\n",
    "col_cutoff_ix = [ix for ix, count in enumerate(word_count_list) if count > cutoff]\n",
    "\n",
    "print('Number of words w/counts above {} : {}'.format(cutoff, len(col_cutoff_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of document-term matrix before trimming: (160000, 151526)\n",
      "Shape of document-term matrix after trimming: (160000, 6095)\n"
     ]
    }
   ],
   "source": [
    "# Get the trimmed vocabulary\n",
    "vocab_trimmed = np.array([vocab[x] for x in col_cutoff_ix])\n",
    "# Re-do the vocab-sorter\n",
    "vocab_sorter_trimmed = np.argsort(vocab_trimmed)\n",
    "\n",
    "print('Shape of document-term matrix before trimming: {}'.format(doc_term_mat.shape))\n",
    "\n",
    "# Trim the document-term matrix\n",
    "doc_term_mat_trimmed = doc_term_mat.tocsc()[:,col_cutoff_ix]\n",
    "\n",
    "print('Shape of document-term matrix after trimming: {}'.format(doc_term_mat_trimmed.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count of words for each appearance\n",
    "hist_breaks = np.arange(0, 500, 10)\n",
    "plt.hist(word_count_list, bins = hist_breaks)\n",
    "plt.title('Histogram of word counts < 500')\n",
    "plt.show()\n",
    "\n",
    "# Too many words appear few times. Check out trimmed.\n",
    "trimmed_word_counts = doc_term_mat_trimmed.sum(axis=0)\n",
    "trimmed_word_list = trimmed_word_counts.tolist()[0]\n",
    "hist_breaks = np.arange(0, 500, 5)\n",
    "plt.hist(trimmed_word_list, bins = hist_breaks)\n",
    "plt.title('Histogram of trimmed word counts < 500')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the TFIDF vectorizer.\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True,\n",
    "                             max_df=0.5,\n",
    "                             max_features=len(col_cutoff_ix),\n",
    "                             stop_words='english')\n",
    "\n",
    "# Fit the vectorizer over the dataset\n",
    "clean_texts = df['clean_tweet']\n",
    "tf_idf_tweets = vectorizer.fit_transform(clean_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Generate word cloud for positive sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>A TF-IDF features matrix is prepared above for the data covering both sentiments.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Generate word cloud for negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>A TF-IDF features matrix is prepared above for the data covering both sentiments.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Split data into 70% for training and 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into train-test. Please wait!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# For training: 107,000 tweets to predict the 0,1 sentiment. \n",
    "# The remaining 53,000 cases to evaluate the model.\n",
    "print('Splitting into train-test. Please wait!')\n",
    "y_targets = np.array([y[0] for y in tweet_data])\n",
    "# Generate 53,000 random row indices\n",
    "X_train, X_test, y_train, y_test = train_test_split(tf_idf_tweets,\n",
    "                                                    y_targets,\n",
    "                                                    test_size=53000,\n",
    "                                                    random_state=42)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Build a classifier that classifies the sentiment of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a standard Logistic Model training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# train a logistic classifier on the data\n",
    "print('Starting a standard Logistic Model training!')\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: What is the accuracy of your model when applied to testing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute results on the train and test set\n",
    "train_probs = lr.predict_proba(X_train)\n",
    "train_results = np.argmax(train_probs, axis=1)\n",
    "\n",
    "test_probs = lr.predict_proba(X_test)\n",
    "test_results = np.argmax(test_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7813831775700935\n",
      "Test accuracy: 0.7545660377358491\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracies\n",
    "train_logical_correct = [pred == actual for pred, actual in zip(train_results, y_train)]\n",
    "train_acc = np.mean(train_logical_correct)\n",
    "\n",
    "test_logical_correct = [pred == actual for pred, actual in zip(test_results, y_test)]\n",
    "test_acc = np.mean(test_logical_correct)\n",
    "\n",
    "print('Train accuracy: {}'.format(train_acc))\n",
    "print('Test accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19298  7283]\n",
      " [ 5725 20694]]\n",
      "===================================\n",
      "             Class 1   -   Class 0\n",
      "Precision: [0.77121049 0.73967902]\n",
      "Recall   : [0.7260073 0.7832999]\n",
      "F1       : [0.74792652 0.76086477]\n",
      "Support  : [26581 26419]\n"
     ]
    }
   ],
   "source": [
    "# Precision is the proportion of correct predictions among all predicted\n",
    "# Recall (sensitivity) is the proportion of correct predictions among all true actual examples\n",
    "# F1 is the harmonic average of precision and recall\n",
    "# Support is count of actual cases of specific class\n",
    "# Here, each of the following is a pair of numbers, the first is for class 1 ('1') and second for class 0 ('0')\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_test, test_results)\n",
    "\n",
    "# Get the parts of the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, test_results).ravel()\n",
    "\n",
    "# Print results\n",
    "print(confusion_matrix(y_test, test_results))\n",
    "print('='*35)\n",
    "print('             Class 1   -   Class 0')\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall   : {}'.format(recall))\n",
    "print('F1       : {}'.format(f1))\n",
    "print('Support  : {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training regularized logistic regression\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# An attempt to improve the results with regularization\n",
    "# to get rid of the discrepancy between train accuracy and test accuracy\n",
    "\n",
    "print('Starting training regularized logistic regression')\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "lr_reg = SGDClassifier(loss='log', penalty='elasticnet', alpha=0.0001, l1_ratio=0.15)\n",
    "lr_reg.fit(X_train, y_train)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute results on the train and test set\n",
    "train_probs = lr_reg.predict_proba(X_train)\n",
    "train_results = np.argmax(train_probs, axis=1)\n",
    "\n",
    "test_probs = lr_reg.predict_proba(X_test)\n",
    "test_results = np.argmax(test_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7540654205607477\n",
      "Test accuracy: 0.7462452830188679\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracies\n",
    "train_logical_correct = [pred == actual for pred, actual in zip(train_results, y_train)]\n",
    "train_acc = np.mean(train_logical_correct)\n",
    "\n",
    "test_logical_correct = [pred == actual for pred, actual in zip(test_results, y_test)]\n",
    "test_acc = np.mean(test_logical_correct)\n",
    "\n",
    "print('Train accuracy: {}'.format(train_acc))\n",
    "print('Test accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18872  7709]\n",
      " [ 5740 20679]]\n",
      "===================================\n",
      "             Class 1   -   Class 0\n",
      "Precision: [0.76678043 0.7284416 ]\n",
      "Recall   : [0.70998081 0.78273212]\n",
      "F1       : [0.7372883  0.75461164]\n",
      "Support  : [26581 26419]\n"
     ]
    }
   ],
   "source": [
    "# Precision is the proportion of correct predictions among all predicted\n",
    "# Recall (sensitivity) is the proportion of correct predictions among all true actual examples\n",
    "# F1 is the harmonic average of precision and recall\n",
    "# Support is count of actual cases of specific class\n",
    "# Here, each of the following is a pair of numbers, the first is for class 1 ('1') and second for class 0 ('0')\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_test, test_results)\n",
    "\n",
    "# Get the parts of the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, test_results).ravel()\n",
    "\n",
    "# Print results\n",
    "print(confusion_matrix(y_test, test_results))\n",
    "print('='*35)\n",
    "print('             Class 1   -   Class 0')\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall   : {}'.format(recall))\n",
    "print('F1       : {}'.format(f1))\n",
    "print('Support  : {}'.format(support))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: What conclusions can you draw from the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>From the results of the model, I conclude that its predictive ability doesn't look good, with the proportion of misclassified sentiments being almost 30%.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Is it better to have a model per source?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>I don't understand what 'source' means here, but I will assume that a 'source' is the domain from which the data is sourced and used to train the model. In such case, the obvious answer would be yes, it is the only way. A model should be trained, tested and used on the data from the same domain (or source), otherwise it will not be able to make accurate predictions because it is not possible to predict market prices for oil by a model trained on movie reviews.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on the applicability of the model on future tweets\n",
    "\n",
    "Given the overall inaccuracy of the model, I am pessimistic about its usefulness for predicting sentiments in future tweets. The model might probably be used for aggregate predictions, for example, along the lines that a larger amount of tweets seems to be positive.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
